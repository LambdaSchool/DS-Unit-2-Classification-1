{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.preprocessing import StandardScaler as ss, RobustScaler as rs\n",
    "from sklearn.model_selection import train_test_split as tts, GridSearchCV as GSCV\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC, GradientBoostingClassifier as GBC\n",
    "import category_encoders as ce\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 40), (59400, 2), (14358, 40), (14358, 2))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pd.read_csv('https://drive.google.com/uc?export=download&id=14ULvX0uOgftTB2s97uS8lIx1nHGQIB0P')\n",
    "train_labels = pd.read_csv('https://drive.google.com/uc?export=download&id=1r441wLr7gKGHGLyPpKauvCuUOU556S2f')\n",
    "test_features = pd.read_csv('https://drive.google.com/uc?export=download&id=1wvsYl9hbRbZuIuoaLWCsW_kbcxCdocHz')\n",
    "sample_submission = pd.read_csv('https://drive.google.com/uc?export=download&id=1kfJewnmhowpUo381oSn3XqsQ6Eto23XV')\n",
    "train_features.shape, train_labels.shape, test_features.shape, sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 32259\n",
       "non functional             22824\n",
       "functional needs repair     4317\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels['baseline'] = 'functional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh                   0\n",
       "date_recorded                0\n",
       "funder                    3635\n",
       "gps_height                   0\n",
       "installer                 3655\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "num_private                  0\n",
       "basin                        0\n",
       "subvillage                 371\n",
       "region                       0\n",
       "region_code                  0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                   0\n",
       "public_meeting            3334\n",
       "recorded_by                  0\n",
       "scheme_management         3877\n",
       "scheme_name              28166\n",
       "permit                    3056\n",
       "construction_year            0\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 41), (14358, 41))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['year'] = train_features['construction_year'].map(lambda x: np.nan if x == 0 else int(x))\n",
    "test_features['year'] = test_features['construction_year'].map(lambda x: np.nan if x == 0 else int(x))\n",
    "train_year_mean = int(train_features['year'].mean(skipna=True))\n",
    "test_year_mean = int(test_features['year'].mean(skipna=True))\n",
    "train_features['year'] = train_features['year'].fillna(train_year_mean)\n",
    "test_features['year'] = test_features['year'].fillna(test_year_mean)\n",
    "train_features['year'] = train_features['year'].astype(int)\n",
    "test_features['year'] = test_features['year'].astype(int)\n",
    "train_features['year'] = pd.to_datetime(train_features['year'], format='%Y')\n",
    "test_features['year'] = pd.to_datetime(test_features['year'], format='%Y')\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-06-05 13:02:52.086935')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = pd.Timestamp.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 42), (14358, 42))"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['age'] = (now - train_features['year']).dt.days\n",
    "test_features['age'] = (now - test_features['year']).dt.days\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_zero_mean(df, training, feature):\n",
    "    df[feature] = df[feature].map(lambda x: np.nan if x == 0 else x)\n",
    "    df[feature].fillna(training[feature].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 42), (14358, 42))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['population'] = train_features['population'].map(lambda x: np.nan if x == 0 else x)\n",
    "test_features['population'] = test_features['population'].map(lambda x: np.nan if x == 0 else x)\n",
    "train_features['population'].fillna(train_features['population'].mean(skipna=True), inplace=True)\n",
    "test_features['population'].fillna(test_features['population'].mean(skipna=True), inplace=True)\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_zero_mean(train_features, train_features, 'population')\n",
    "replace_zero_mean(test_features, train_features, 'population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 43), (14358, 43))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['date_recorded'] = pd.to_datetime(train_features['date_recorded'])\n",
    "test_features['date_recorded'] = pd.to_datetime(test_features['date_recorded'])\n",
    "train_features['since_recording'] = (now - train_features['date_recorded']).dt.days\n",
    "test_features['since_recording'] = (now - test_features['date_recorded']).dt.days\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3005\n",
       "1    2282\n",
       "2    2291\n",
       "3    2319\n",
       "4    2884\n",
       "Name: since_recording, dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['since_recording'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 42), (14358, 42))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = train_features.drop(columns='construction_year')\n",
    "test_features = test_features.drop(columns='construction_year')\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_zero_mean(train_features, train_features, 'latitude')\n",
    "replace_zero_mean(test_features, train_features, 'latitude')\n",
    "replace_zero_mean(train_features, train_features, 'longitude')\n",
    "replace_zero_mean(test_features, train_features, 'longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features['latitude_bins'] = pd.cut(train_features['latitude'], 20, labels=[str(x) for x in range(20)])\n",
    "# test_features['latitude_bins'] = pd.cut(test_features['latitude'], 20, labels=[str(x) for x in range(20)])\n",
    "\n",
    "# train_features['longitude_bins'] = pd.cut(train_features['longitude'], 20, labels=[str(x) for x in range(20)])\n",
    "# test_features['longitude_bins'] = pd.cut(test_features['longitude'], 20, labels=[str(x) for x in range(20)])\n",
    "# train_features['latitude_bins'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_zero_mean(train_features, train_features, 'amount_tsh')\n",
    "replace_zero_mean(test_features, train_features, 'amount_tsh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace_zero_mean(train_features, train_features, 'gps_height')\n",
    "# replace_zero_mean(test_features, train_features, 'gps_height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.drop(columns=['date_recorded', 'year'])\n",
    "test_features = test_features.drop(columns=['date_recorded', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_features = ['amount_tsh',\n",
    "#                 'gps_height',\n",
    "#                 'num_private',\n",
    "#                 'region_code',\n",
    "#                 'district_code',\n",
    "#                 'population',\n",
    "#                 'age']\n",
    "# pca_data = PCA(n_components=4).fit_transform(train_features[pca_features])\n",
    "\n",
    "# pca_test = PCA(n_components=4).fit_transform(test_features[pca_features])\n",
    "\n",
    "# train_features = train_features.drop(columns=pca_features)\n",
    "# test_features = test_features.drop(columns=pca_features)\n",
    "\n",
    "# for i in range(pca_data.shape[1]):\n",
    "#     train_features[f'pc{i}'] = pca_data[:,i]\n",
    "#     test_features[f'pc{i}'] = pca_test[:,i]\n",
    "# test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41580, 40) (17820, 40) (41580,) (17820,) (14358, 40)\n",
      "(41580, 40) (17820, 40) (14358, 40)\n"
     ]
    }
   ],
   "source": [
    "cat_features = [\n",
    "                'source_type',\n",
    "                'quality_group',\n",
    "                'extraction_type',\n",
    "                'quantity_group',\n",
    "                'management_group',\n",
    "                'basin',\n",
    "                'payment_type',\n",
    "                'permit',\n",
    "                'installer'\n",
    "#                 'scheme_management'\n",
    "                ]\n",
    "num_features = [\n",
    "                'amount_tsh',\n",
    "                'gps_height',\n",
    "                'longitude',\n",
    "                'latitude',\n",
    "                'num_private',\n",
    "                'region_code',\n",
    "                'district_code',\n",
    "                'population',\n",
    "                'age',\n",
    "#                 'since_recording'\n",
    "               ]\n",
    "# num_features = ['pc0', 'pc1', 'pc2', 'pc3']\n",
    "# features = cat_features + num_features\n",
    "\n",
    "train = train_features\n",
    "y_train = train_labels['status_group']\n",
    "\n",
    "test = test_features\n",
    "\n",
    "X_train, X_val, y_train, y_val = tts(train,\n",
    "                                     y_train,\n",
    "                                     train_size=.7,\n",
    "                                     test_size=.3,\n",
    "                                     stratify=y_train,\n",
    "                                     random_state=42)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape, test.shape)\n",
    "\n",
    "encoder = ce.OrdinalEncoder()\n",
    "X_train_enc = encoder.fit_transform(X_train)\n",
    "X_val_enc = encoder.transform(X_val)\n",
    "X_test_features = encoder.transform(test)\n",
    "print(X_train_enc.shape, X_val_enc.shape, X_test_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = RFC(n_jobs=-1,\n",
    "            n_estimators=250,\n",
    "            min_samples_leaf=3,\n",
    "#             min_samples_split=.6,\n",
    "            max_features=.75,\n",
    "            criterion='entropy',\n",
    "#             random_state=42,\n",
    "            bootstrap=True,\n",
    "            max_depth=24,\n",
    "#             class_weight='balanced',\n",
    "            verbose=1,\n",
    "            )\n",
    "# parameters = {'n_estimators': range(100, 251, 50),\n",
    "#               'min_samples_leaf': range(3, 7),\n",
    "#               'criterion': ('entropy', 'gini'),\n",
    "#               'max_features': [x / 100 for x in range(85, 100, 5)],\n",
    "#               'min_samples_split': range(5, 13),\n",
    "#               'bootstrap': (True, False),\n",
    "#               }\n",
    "# clf = GSCV(model,\n",
    "#            parameters, \n",
    "#            cv=3,\n",
    "#            n_jobs=-1,\n",
    "#            verbose=3,\n",
    "#            )\n",
    "\n",
    "# clf.fit(X_train_enc, y_train)\n",
    "model.fit(X_train_enc, y_train)\n",
    "print(model.score(X_val_enc, y_val))\n",
    "# print(clf.best_estimator_, clf.best_score_, clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.score(X_val_enc, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.543080808080808"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(train_labels['status_group'], train_labels['baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicted = model.predict(X_test_features)\n",
    "# submission = sample_submission.copy()\n",
    "# submission['status_group'] = predicted\n",
    "# submission.to_csv('sub_7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
