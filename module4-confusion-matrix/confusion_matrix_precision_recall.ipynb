{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMI2k-oBsS08"
   },
   "source": [
    "_Lambda School Data Science — Classification 1_ \n",
    "\n",
    "This sprint, your project is about water pumps in Tanzania. Can you predict which water pumps are faulty?\n",
    "\n",
    "# Confusion Matrix, Precision & Recall\n",
    "\n",
    "#### Objectives\n",
    "- get and interpret the confusion matrix for classification models\n",
    "- use classification metrics: precision, recall\n",
    "- understand the relationships between precision, recall, thresholds, and predicted probabilities\n",
    "- understand how Precision@K can help make decisions and allocate budgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rU7RuVcjWdcp"
   },
   "source": [
    "#### Install category_encoders\n",
    "- Local, Anaconda: `conda install -c conda-forge category_encoders`\n",
    "- Google Colab: `pip install category_encoders`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: Load data, fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.8140409527789386\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def wrangle(X):\n",
    "    \"\"\"Wrangles train, validate, and test sets in the same way\"\"\"\n",
    "    X = X.copy()\n",
    "\n",
    "    # Convert date_recorded to datetime\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract components from date_recorded, then drop the original column\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    X['month_recorded'] = X['date_recorded'].dt.month\n",
    "    X['day_recorded'] = X['date_recorded'].dt.day\n",
    "    X = X.drop(columns='date_recorded')\n",
    "    \n",
    "    # Engineer feature: how many years from construction_year to date_recorded\n",
    "    X['years'] = X['year_recorded'] - X['construction_year']    \n",
    "    \n",
    "    # Drop recorded_by (never varies) and id (always varies, random)\n",
    "    unusable_variance = ['recorded_by', 'id']\n",
    "    X = X.drop(columns=unusable_variance)\n",
    "    \n",
    "    # Drop duplicate columns\n",
    "    duplicate_columns = ['quantity_group']\n",
    "    X = X.drop(columns=duplicate_columns)\n",
    "    \n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these like null values\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, np.nan)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values\n",
    "    cols_with_zeros = ['construction_year', 'longitude', 'latitude', 'gps_height', 'population']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        \n",
    "    # For categoricals with missing values, fill with the category 'MISSING'\n",
    "    categoricals = X.select_dtypes(exclude='number').columns\n",
    "    for col in categoricals:\n",
    "        X[col] = X[col].fillna('MISSING')\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "# Merge train_features.csv & train_labels.csv\n",
    "train = pd.merge(pd.read_csv('https://drive.google.com/uc?export=download&id=14ULvX0uOgftTB2s97uS8lIx1nHGQIB0P'), \n",
    "                 pd.read_csv('https://drive.google.com/uc?export=download&id=1r441wLr7gKGHGLyPpKauvCuUOU556S2f'))\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "test = pd.read_csv('https://drive.google.com/uc?export=download&id=1wvsYl9hbRbZuIuoaLWCsW_kbcxCdocHz')\n",
    "sample_submission = pd.read_csv('https://drive.google.com/uc?export=download&id=1kfJewnmhowpUo381oSn3XqsQ6Eto23XV')\n",
    "\n",
    "# Split train into train & val. Make val the same size as test.\n",
    "train, val = train_test_split(train, test_size=len(test),  \n",
    "                              stratify=train['status_group'], random_state=42)\n",
    "\n",
    "# Wrangle train, validate, and test sets in the same way\n",
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test)\n",
    "\n",
    "# Arrange data into X features matrix and y target vector\n",
    "target = 'status_group'\n",
    "b\n",
    "\n",
    "# Make pipeline!\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='mean'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# Fit on train, score on val\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_val)\n",
    "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bf9311794e63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and interpret the confusion matrix for classification models\n",
    "\n",
    "[Scikit-Learn User Guide — Confusion Matrix](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7005</td>\n",
       "      <td>171</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>555</td>\n",
       "      <td>332</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1098</td>\n",
       "      <td>68</td>\n",
       "      <td>4351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1     2\n",
       "0  7005  171   622\n",
       "1   555  332   156\n",
       "2  1098   68  4351"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_val, y_pred), columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many correct predictions were made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['functional', 'functional needs repair', 'non functional'],\n",
       "      dtype='<U23')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import unique_labels \n",
    "\n",
    "unique_labels(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many total predictions were made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['functional', 'functional needs repair', 'non functional'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.named_steps['randomforestclassifier'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was the classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use classification metrics: precision, recall\n",
    "[Scikit-Learn User Guide — Classification Report](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['funder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "      <th>year_recorded</th>\n",
       "      <th>month_recorded</th>\n",
       "      <th>day_recorded</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>33.075583</td>\n",
       "      <td>-9.385449</td>\n",
       "      <td>Kwa Mwazembe</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Itaba</td>\n",
       "      <td>Mbeya</td>\n",
       "      <td>...</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>non functional</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26326</th>\n",
       "      <td>500.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>DWE</td>\n",
       "      <td>36.228574</td>\n",
       "      <td>-8.207742</td>\n",
       "      <td>Kwamwampwaga</td>\n",
       "      <td>0</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Igima</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>...</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>non functional</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53251</th>\n",
       "      <td>0.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>FinW</td>\n",
       "      <td>39.673635</td>\n",
       "      <td>-10.835281</td>\n",
       "      <td>Pachani</td>\n",
       "      <td>0</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mnyekehe</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>...</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>non functional</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26791</th>\n",
       "      <td>500.0</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>DWE</td>\n",
       "      <td>34.915589</td>\n",
       "      <td>-9.016965</td>\n",
       "      <td>Kwa Mwangayange Mfumbilwa</td>\n",
       "      <td>0</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Ndanula</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>...</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>200.0</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>DWE</td>\n",
       "      <td>30.332034</td>\n",
       "      <td>-4.308921</td>\n",
       "      <td>Kwa Bungwa</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Tanganyika</td>\n",
       "      <td>Nyakerera</td>\n",
       "      <td>Kigoma</td>\n",
       "      <td>...</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount_tsh  gps_height installer  longitude   latitude  \\\n",
       "45793         0.0         NaN   MISSING  33.075583  -9.385449   \n",
       "26326       500.0       285.0       DWE  36.228574  -8.207742   \n",
       "53251         0.0       218.0      FinW  39.673635 -10.835281   \n",
       "26791       500.0      1704.0       DWE  34.915589  -9.016965   \n",
       "2162        200.0      1232.0       DWE  30.332034  -4.308921   \n",
       "\n",
       "                        wpt_name  num_private                    basin  \\\n",
       "45793               Kwa Mwazembe            0               Lake Nyasa   \n",
       "26326               Kwamwampwaga            0                   Rufiji   \n",
       "53251                    Pachani            0  Ruvuma / Southern Coast   \n",
       "26791  Kwa Mwangayange Mfumbilwa            0                   Rufiji   \n",
       "2162                  Kwa Bungwa            0          Lake Tanganyika   \n",
       "\n",
       "      subvillage    region  ...          source   source_type source_class  \\\n",
       "45793      Itaba     Mbeya  ...    shallow well  shallow well  groundwater   \n",
       "26326      Igima  Morogoro  ...    shallow well  shallow well  groundwater   \n",
       "53251   Mnyekehe    Mtwara  ...     machine dbh      borehole  groundwater   \n",
       "26791    Ndanula    Iringa  ...          spring        spring  groundwater   \n",
       "2162   Nyakerera    Kigoma  ...          spring        spring  groundwater   \n",
       "\n",
       "                   waterpoint_type  waterpoint_type_group    status_group  \\\n",
       "45793                    hand pump              hand pump  non functional   \n",
       "26326                    hand pump              hand pump  non functional   \n",
       "53251  communal standpipe multiple     communal standpipe  non functional   \n",
       "26791           communal standpipe     communal standpipe      functional   \n",
       "2162            communal standpipe     communal standpipe      functional   \n",
       "\n",
       "      year_recorded month_recorded day_recorded  years  \n",
       "45793          2011              3           30   2011  \n",
       "26326          2011              2           28     27  \n",
       "53251          2013              1           27     31  \n",
       "26791          2011              2           27      3  \n",
       "2162           2013              1           18     10  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.81      0.90      0.85      7798\n",
      "functional needs repair       0.58      0.32      0.41      1043\n",
      "         non functional       0.85      0.79      0.82      5517\n",
      "\n",
      "              micro avg       0.81      0.81      0.81     14358\n",
      "              macro avg       0.75      0.67      0.69     14358\n",
      "           weighted avg       0.81      0.81      0.81     14358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikipedia, [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "\n",
    "> Both precision and recall are based on an understanding and measure of relevance.\n",
    "\n",
    "> Suppose a computer program for recognizing dogs in photographs identifies 8 dogs in a picture containing 12 dogs and some cats. Of the 8 identified as dogs, 5 actually are dogs (true positives), while the rest are cats (false positives). The program's precision is 5/8 while its recall is 5/12.\n",
    "\n",
    "> High precision means that an algorithm returned substantially more relevant results than irrelevant ones, while high recall means that an algorithm returned most of the relevant results.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [We can get precision & recall from the confusion matrix](https://en.wikipedia.org/wiki/Precision_and_recall#Definition_(classification_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many correct predictions of \"non functional\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many total predictions of \"non functional\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's the precision for \"non functional\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many actual \"non functional\" waterpumps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's the recall for \"non functional\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the relationships between precision, recall, thresholds, and predicted probabilities. Understand how Precision@K can help make decisions and allocate budgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagine this scenario...\n",
    "\n",
    "Suppose there are over 14,000 waterpumps that you _do_ have some information about, but you _don't_ know whether they are currently functional, or functional but need repair, or non-functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You have the time and resources to go to just 2,000 waterpumps for proactive maintenance.** You want to predict, which 2,000 are most likely non-functional or in need of repair, to help you triage and prioritize your waterpump inspections.\n",
    "\n",
    "You have historical inspection data for over 59,000 other waterpumps, which you'll use to fit your predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train) + len(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have historical inspection data for over 59,000 other waterpumps, which you'll use to fit your predictive model.\n",
    "\n",
    "Based on this historical data, if you randomly chose waterpumps to inspect, then about 46% of the waterpumps would need repairs, and 54% would not need repairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can you do better than random at prioritizing inspections?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, we should define our target differently. We want to identify which waterpumps are non-functional _or_ are functional but needs repair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train != 'functional'\n",
    "y_val = y_val != 'functional'\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already made our validation set the same size as our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val) == len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can refit our model, using the redefined target.\n",
    "\n",
    "Then make predictions for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many total predictions of \"True\" (\"non functional\" or \"functional needs repair\") ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We don't have \"budget\" to take action on all these predictions\n",
    "\n",
    "- But we can get predicted probabilities, to rank the predictions. \n",
    "- Then change the threshold, to change the number of positive predictions, based on our budget."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predicted probabilities and plot the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this scenario ... \n",
    "\n",
    "Accuracy _isn't_ the best metric!\n",
    "\n",
    "Instead, change the threshold, to change the number of positive predictions, based on the budget. (You have the time and resources to go to just 2,000 waterpumps for proactive maintenance.)\n",
    "\n",
    "Then, evaluate with the precision for \"non functional\"/\"functional needs repair\".\n",
    "\n",
    "This is conceptually like **Precision@K**, where k=2,000.\n",
    "\n",
    "Read more here: [Recall and Precision at k for Recommender Systems: Detailed Explanation with examples](https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54)\n",
    "\n",
    "> Precision at k is the proportion of recommended items in the top-k set that are relevant\n",
    "\n",
    "> Mathematically precision@k is defined as: `Precision@k = (# of recommended items @k that are relevant) / (# of recommended items @k)`\n",
    "\n",
    "> In the context of recommendation systems we are most likely interested in recommending top-N items to the user. So it makes more sense to compute precision and recall metrics in the first N items instead of all the items. Thus the notion of precision and recall at k where k is a user definable integer that is set by the user to match the top-N recommendations objective.\n",
    "\n",
    "We asked, can you do better than random at prioritizing inspections?\n",
    "\n",
    "If we had randomly chosen waterpumps to inspect, we estimate that only 920 waterpumps would be repaired after 2,000 maintenance visits. (46%)\n",
    "\n",
    "But using our predictive model, in the validation set, we succesfully identified over 1,600 waterpumps in need of repair!\n",
    "\n",
    "So we will use this predictive model with the dataset of over 14,000 waterpumps that we _do_ have some information about, but we _don't_ know whether they are currently functional, or functional but need repair, or non-functional.\n",
    "\n",
    "We will predict which 2,000 are most likely non-functional or in need of repair.\n",
    "\n",
    "We estimate that approximately 1,600 waterpumps will be repaired after these 2,000 maintenance visits.\n",
    "\n",
    "So we're confident that our predictive model will help triage and prioritize waterpump inspections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_XjBTW5SBwZ"
   },
   "source": [
    "# Assignment\n",
    "- Submit your final predictions to your Kaggle competition! Commit your notebook to your fork of the GitHub repo.\n",
    "- Read [Maximizing Scarce Maintenance Resources with Data: Applying predictive modeling, precision at k, and clustering to optimize impact](https://towardsdatascience.com/maximizing-scarce-maintenance-resources-with-data-8f3491133050), by Lambda DS3 student Michael Brady. His blog post extends the Tanzania Waterpumps scenario, far beyond what's in this lecture notebook.\n",
    "\n",
    "## Stretch goals — Highly Recommended Links\n",
    "- Read Google Research's blog post, [Attacking discrimination with smarter machine learning](https://research.google.com/bigpicture/attacking-discrimination-in-ml/), and explore the interactive visualizations. _\"A threshold classifier essentially makes a yes/no decision, putting things in one category or another. We look at how these classifiers work, ways they can potentially be unfair, and how you might turn an unfair classifier into a fairer one. As an illustrative example, we focus on loan granting scenarios where a bank may grant or deny a loan based on a single, automatically computed number such as a credit score.\"_\n",
    "- Read the blog post, [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415). You can replicate the code as-is,  [\"the hard way\"](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit). Or you can apply it to the Tanzania Waterpumps data.\n",
    "- Read this [notebook about how to calculate expected value from a confusion matrix by treating it as a cost-benefit matrix](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb). We'll learn more about this in our Classification 2 sprint, when we predict if peer-to-peer loans are charged off or fully paid, and decide which loans to invest in.\n",
    "- (Re)read the [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) and watch the 35 minute video."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_242_Validate_classification_problems.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
