{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==0.23.4\n",
      "  Downloading https://files.pythonhosted.org/packages/58/a8/03e5fe0edbc522e46cb27df2abfb4266814129253d8462f38bc704a76a2a/pandas-0.23.4-cp37-cp37m-win_amd64.whl (7.9MB)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\lilyx\\anaconda3\\lib\\site-packages (from pandas==0.23.4) (1.16.2)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\lilyx\\appdata\\roaming\\python\\python37\\site-packages (from pandas==0.23.4) (2018.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\lilyx\\appdata\\roaming\\python\\python37\\site-packages (from pandas==0.23.4) (2.7.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lilyx\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.5.0->pandas==0.23.4) (1.11.0)\n",
      "Installing collected packages: pandas\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "Successfully installed pandas-0.23.4\n",
      "Collecting graphviz\n",
      "  Downloading https://files.pythonhosted.org/packages/af/ae/e1c63ac4c531d69a7960a99af99e184d4f3da15e29f67767c4252bf19cce/graphviz-0.11-py2.py3-none-any.whl\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==0.23.4\n",
    "!pip install graphviz\n",
    "!apt-get install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "AjlfVsQRyhhc",
    "outputId": "8890e037-b116-4dc6-f7ea-04221d2868ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\lilyx\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - category_encoders\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    category_encoders-1.3.0    |             py_0          29 KB  conda-forge\n",
      "    certifi-2019.3.9           |           py37_0         149 KB  conda-forge\n",
      "    conda-4.6.14               |           py37_0         2.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  category_encoders  conda-forge/noarch::category_encoders-1.3.0-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                      pkgs/main::conda-4.6.11-py37_0 --> conda-forge::conda-4.6.14-py37_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                         pkgs/main --> conda-forge\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "conda-4.6.14         | 2.1 MB    |            |   0% \n",
      "conda-4.6.14         | 2.1 MB    | ###5       |  35% \n",
      "conda-4.6.14         | 2.1 MB    | #######8   |  78% \n",
      "conda-4.6.14         | 2.1 MB    | #########8 |  98% \n",
      "conda-4.6.14         | 2.1 MB    | ########## | 100% \n",
      "\n",
      "certifi-2019.3.9     | 149 KB    |            |   0% \n",
      "certifi-2019.3.9     | 149 KB    | ########## | 100% \n",
      "\n",
      "category_encoders-1. | 29 KB     |            |   0% \n",
      "category_encoders-1. | 29 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "(base) C:\\Users\\lilyx\\Desktop\\Water>ET _sysp=%~dpA \n",
      "\n",
      "(base) C:\\Users\\lilyx\\Desktop\\Water>IF NOT EXIST \"!_sysp!\\Scripts\\conda.exe\" \n",
      "Collecting package metadata: ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The conda.compat module is deprecated and will be removed in a future release.\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.6.11\n",
      "  latest version: 4.6.14\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "'ET' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge category_encoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "HBCh3uDyykhT",
    "outputId": "262c2314-456d-4192-e900-df868e288367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (47520, 55)\n",
      "val (11880, 55)\n",
      "test (14358, 55)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# Merge train_features.csv & train_labels.csv\n",
    "train = pd.merge(pd.read_csv('https://drive.google.com/uc?export=download&id=14ULvX0uOgftTB2s97uS8lIx1nHGQIB0P'), \n",
    "                 pd.read_csv('https://drive.google.com/uc?export=download&id=1r441wLr7gKGHGLyPpKauvCuUOU556S2f'))\n",
    "\n",
    "pop1 = pd.read_csv('tza_pop_adm1.csv')\n",
    "pop2 = pd.read_csv('tza_pop_adm2.csv')\n",
    "pop3 = pd.read_csv('tza_pop_adm3.csv')\n",
    "\n",
    "trainwithpopulation1 = pd.merge(train, pop1, how='outer', left_on = 'region', right_on = 'ADM1_EN')\n",
    "train = trainwithpopulation1.iloc[0:59400]\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "test = pd.read_csv('https://drive.google.com/uc?export=download&id=1wvsYl9hbRbZuIuoaLWCsW_kbcxCdocHz')\n",
    "sample_submission = pd.read_csv('https://drive.google.com/uc?export=download&id=1kfJewnmhowpUo381oSn3XqsQ6Eto23XV')\n",
    "\n",
    "testwithpopulation1 = pd.merge(test, pop1, how='outer', left_on = 'region', right_on = 'ADM1_EN')\n",
    "test = trainwithpopulation1.iloc[0:14358]\n",
    "\n",
    "# Split train into train & val\n",
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
    "                              stratify=train['status_group'], random_state=42)\n",
    "\n",
    "# Print dataframe shapes\n",
    "print('train', train.shape)\n",
    "print('val', val.shape)\n",
    "print('test', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4R9FGQ2ynMT"
   },
   "outputs": [],
   "source": [
    "def wrangle(X):\n",
    "    \"\"\"Wrangles train, validate, and test sets in the same way\"\"\"\n",
    "    X = X.copy()\n",
    "    \n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these values like zero.\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values.\n",
    "    # So we will replace them with the column mean.\n",
    "    cols_with_zeros = ['construction_year', 'longitude', 'latitude']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        X[col] = X[col].fillna(X[col].mean())#using the average of a specific district\n",
    "        \n",
    "    # Convert date_recorded to datetime\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract year from date_recorded\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    #Extract Never payed in separate column\n",
    "    X['neverpay'] = X['payment'] == 'never pay'\n",
    "    \n",
    "    # quantity & quantity_group are duplicates, so drop one\n",
    "    X = X.drop(['quantity_group','ADM1_EN', 'date_recorded', 'region_code',\n",
    "                'district_code','recorded_by','scheme_management', 'scheme_name',\n",
    "                'extraction_type_group','management','management_group',\n",
    "                'ADM1_PCODE', 'ADM0_PCODE','TOTAL_BOTH','URBAN_BOTH','population'], axis=1)\n",
    "    \n",
    "    \n",
    "    # for categoricals with missing values, fill with the category 'MISSING'\n",
    "    categoricals = X.select_dtypes(exclude='number').columns\n",
    "    for col in categoricals:\n",
    "        X[col] = X[col].fillna('MISSING')\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSQGIH84yvAq"
   },
   "outputs": [],
   "source": [
    "#impute\n",
    "train = train.fillna(0)\n",
    "val = val.fillna(0)\n",
    "test = test.fillna(0)\n",
    "\n",
    "# The status_group column is the target\n",
    "target = 'status_group'\n",
    "\n",
    "# Get a dataframe with all train columns except the target & id\n",
    "train_features = train.drop(columns=[target, 'id'])\n",
    "\n",
    "# Get a list of the numeric features\n",
    "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Get a series with the cardinality of the nonnumeric features\n",
    "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
    "\n",
    "# Get a list of all categorical features with cardinality <= 50\n",
    "categorical_features = cardinality[cardinality <= 20].index.tolist()\n",
    "\n",
    "# Combine the lists \n",
    "features = numeric_features + categorical_features\n",
    "\n",
    "\n",
    "\n",
    "#drop unknowns and missing data\n",
    "# train['neverpay'] = train[train.payment == 'never pay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47520, 41)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMxoCrHly7oK"
   },
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector \n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]\n",
    "\n",
    "# Encoder: fit_transform on train, transform on val & test\n",
    "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_val_encoded = encoder.transform(X_val)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# Scaler: fit_transform on train, transform on val & test\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_val_scaled = scaler.transform(X_val_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47520, 141)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "X_train_scaled['tojoin'] = 1\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled)\n",
    "X_val_scaled['tojoin'] = 1\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled)\n",
    "X_test_scaled['tojoin'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilyx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\lilyx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\lilyx\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_numeric_features_to_array = train_features.select_dtypes(include='number')\n",
    "train_numeric_features_to_array['tojoin'] = 1\n",
    "val_features = val.drop(columns=[target, 'id'])\n",
    "val_numeric_features_to_array = val_features.select_dtypes(include='number')\n",
    "val_numeric_features_to_array['tojoin'] = 1\n",
    "test_features = test.drop(columns=[target, 'id'])\n",
    "test_numeric_features_to_array = test_features.select_dtypes(include='number')\n",
    "test_numeric_features_to_array['tojoin'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47520, 142)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>TOTAL_MALE</th>\n",
       "      <th>TOTAL_FEMA</th>\n",
       "      <th>RURAL_BOTH</th>\n",
       "      <th>RURAL_MALE</th>\n",
       "      <th>URBAN_MALE</th>\n",
       "      <th>URBAN_FEMA</th>\n",
       "      <th>RURAL_FEMA</th>\n",
       "      <th>year_recorded</th>\n",
       "      <th>tojoin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.00</td>\n",
       "      <td>1390.00</td>\n",
       "      <td>34.94</td>\n",
       "      <td>-9.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1999.00</td>\n",
       "      <td>452052.00</td>\n",
       "      <td>489186.00</td>\n",
       "      <td>684890.00</td>\n",
       "      <td>329740.00</td>\n",
       "      <td>122312.00</td>\n",
       "      <td>134036.00</td>\n",
       "      <td>355150.00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500.00</td>\n",
       "      <td>1703.00</td>\n",
       "      <td>34.64</td>\n",
       "      <td>-9.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1978.00</td>\n",
       "      <td>452052.00</td>\n",
       "      <td>489186.00</td>\n",
       "      <td>684890.00</td>\n",
       "      <td>329740.00</td>\n",
       "      <td>122312.00</td>\n",
       "      <td>134036.00</td>\n",
       "      <td>355150.00</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height  longitude  latitude  num_private  \\\n",
       "0     6000.00     1390.00      34.94     -9.86         0.00   \n",
       "1      500.00     1703.00      34.64     -9.11         0.00   \n",
       "\n",
       "   construction_year  TOTAL_MALE  TOTAL_FEMA  RURAL_BOTH  RURAL_MALE  \\\n",
       "0            1999.00   452052.00   489186.00   684890.00   329740.00   \n",
       "1            1978.00   452052.00   489186.00   684890.00   329740.00   \n",
       "\n",
       "   URBAN_MALE  URBAN_FEMA  RURAL_FEMA  year_recorded  tojoin  \n",
       "0   122312.00   134036.00   355150.00           2011       1  \n",
       "1   122312.00   134036.00   355150.00           2011       1  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_numeric_features_to_array.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 142), (47520, 15))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape, train_numeric_features_to_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.merge(X_train_scaled, train_numeric_features_to_array, how='outer', left_index = True, right_index = True)\n",
    "X_val_scaled = pd.merge(X_val_scaled, val_numeric_features_to_array, how='outer', left_index = True, right_index = True)\n",
    "X_test_scaled = pd.merge(X_test_scaled, test_numeric_features_to_array, how='outer', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_scaled = X_train_scaled.iloc[0:47520]\n",
    "X_val_scaled = X_val_scaled.iloc[0:11880]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38100, 157), (2323, 157), (14358, 157), (47520,), (11880,))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled = X_train_scaled.dropna()\n",
    "X_val_scaled = X_val_scaled.dropna()\n",
    "X_test_scaled = X_test_scaled.dropna()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_scaled)\n",
    "X_val_scaled = scaler.fit_transform(X_val_scaled)\n",
    "X_test_scaled = scaler.fit_transform(X_test_scaled)\n",
    "\n",
    "X_train_scaled.shape, X_val_scaled.shape, X_test_scaled.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rkLk0cAP2Nyq",
    "outputId": "e29c224c-ee1e-4fc6-de80-4b0f10294b84"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=47520 does not match number of samples=38100",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-236-6c3d3f2a6450>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Validation Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[1;32m--> 236\u001b[1;33m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0m\u001b[0;32m    237\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"min_weight_fraction_leaf must in [0, 0.5]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels=47520 does not match number of samples=38100"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=14, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print('Train Accuracy', model.score(X_train_scaled, y_train))\n",
    "print('Validation Accuracy', model.score(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ge1pXtMm2L8F"
   },
   "outputs": [],
   "source": [
    "# # Model: Fit on train, score on val, predict on test\n",
    "# model = LogisticRegression(solver='lbfgs', multi_class='auto', n_jobs=-1)\n",
    "# model.fit(X_train_scaled, y_train)\n",
    "# print('Validation Accuracy', model.score(X_val_scaled, y_val))\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Write submission csv file\n",
    "submission = sample_submission.copy()\n",
    "submission['status_group'] = y_pred\n",
    "submission.to_csv('submission-03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPwQdJj4y-KK"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('submission-03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjxRk1XbzPma"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tanzania Water Pump Predictions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
