{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features (59400, 40)\n",
      "train_labels (59400, 2)\n",
      "test_features (14358, 40)\n",
      "sample_submission (14358, 2)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from fancyimpute import IterativeImputer\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Read train_feature.csv, train_labels.csv, test_features.csv, sample_submission.csv\n",
    "train_features = pd.read_csv('https://drive.google.com/uc?export=download&id=14ULvX0uOgftTB2s97uS8lIx1nHGQIB0P')\n",
    "train_labels = pd.read_csv('https://drive.google.com/uc?export=download&id=1r441wLr7gKGHGLyPpKauvCuUOU556S2f')\n",
    "test_features = pd.read_csv('https://drive.google.com/uc?export=download&id=1wvsYl9hbRbZuIuoaLWCsW_kbcxCdocHz')\n",
    "sample_submission = pd.read_csv('https://drive.google.com/uc?export=download&id=1kfJewnmhowpUo381oSn3XqsQ6Eto23XV')\n",
    "\n",
    "# Print dataframe shapes\n",
    "print('train_features', train_features.shape)\n",
    "print('train_labels', train_labels.shape)\n",
    "print('test_features', test_features.shape)\n",
    "print('sample_submission', sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 40), (11880, 40), (47520,), (11880,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_features, train_labels['status_group'],\n",
    "    train_size=0.8, test_size=0.2, \n",
    "    stratify=train_labels['status_group'], \n",
    "    random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data and impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59400.00</td>\n",
       "      <td>59400.00</td>\n",
       "      <td>59400.00</td>\n",
       "      <td>59400.00</td>\n",
       "      <td>59400.00</td>\n",
       "      <td>59400.00</td>\n",
       "      <td>59400.00</td>\n",
       "      <td>59400.00</td>\n",
       "      <td>59400.00</td>\n",
       "      <td>59400.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37115.13</td>\n",
       "      <td>317.65</td>\n",
       "      <td>668.30</td>\n",
       "      <td>34.08</td>\n",
       "      <td>-5.71</td>\n",
       "      <td>0.47</td>\n",
       "      <td>15.30</td>\n",
       "      <td>5.63</td>\n",
       "      <td>179.91</td>\n",
       "      <td>1300.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21453.13</td>\n",
       "      <td>2997.57</td>\n",
       "      <td>693.12</td>\n",
       "      <td>6.57</td>\n",
       "      <td>2.95</td>\n",
       "      <td>12.24</td>\n",
       "      <td>17.59</td>\n",
       "      <td>9.63</td>\n",
       "      <td>471.48</td>\n",
       "      <td>951.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-90.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-11.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18519.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.09</td>\n",
       "      <td>-8.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37061.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>369.00</td>\n",
       "      <td>34.91</td>\n",
       "      <td>-5.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1986.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55656.50</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1319.25</td>\n",
       "      <td>37.18</td>\n",
       "      <td>-3.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>215.00</td>\n",
       "      <td>2004.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74247.00</td>\n",
       "      <td>350000.00</td>\n",
       "      <td>2770.00</td>\n",
       "      <td>40.35</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1776.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>30500.00</td>\n",
       "      <td>2013.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  amount_tsh  gps_height  longitude  latitude  num_private  \\\n",
       "count 59400.00    59400.00    59400.00   59400.00  59400.00     59400.00   \n",
       "mean  37115.13      317.65      668.30      34.08     -5.71         0.47   \n",
       "std   21453.13     2997.57      693.12       6.57      2.95        12.24   \n",
       "min       0.00        0.00      -90.00       0.00    -11.65         0.00   \n",
       "25%   18519.75        0.00        0.00      33.09     -8.54         0.00   \n",
       "50%   37061.50        0.00      369.00      34.91     -5.02         0.00   \n",
       "75%   55656.50       20.00     1319.25      37.18     -3.33         0.00   \n",
       "max   74247.00   350000.00     2770.00      40.35     -0.00      1776.00   \n",
       "\n",
       "       region_code  district_code  population  construction_year  \n",
       "count     59400.00       59400.00    59400.00           59400.00  \n",
       "mean         15.30           5.63      179.91            1300.65  \n",
       "std          17.59           9.63      471.48             951.62  \n",
       "min           1.00           0.00        0.00               0.00  \n",
       "25%           5.00           2.00        0.00               0.00  \n",
       "50%          12.00           3.00       25.00            1986.00  \n",
       "75%          17.00           5.00      215.00            2004.00  \n",
       "max          99.00          80.00    30500.00            2013.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2e-08"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['latitude'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['longitude'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified wrangle() so that it doesn't fill NaN values\n",
    "def wrangle(X):\n",
    "    \"\"\"Wrangles train, validate, and test sets in the same way\"\"\"\n",
    "    X = X.copy()\n",
    "    \n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these values like zero.\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values.\n",
    "    # So we'll make them NaN values and impute them later.\n",
    "    cols_with_zeros = ['construction_year', 'longitude', 'latitude']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        \n",
    "    # Convert date_recorded to datetime\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract year from date_recorded\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    \n",
    "    # quantity & quantity_group are duplicates, so drop one\n",
    "    X = X.drop(columns=['quantity_group','date_recorded'])\n",
    "    \n",
    "    # for categoricals with missing values, fill with the category 'MISSING'\n",
    "    categoricals = X.select_dtypes(exclude='number').columns\n",
    "    for col in categoricals:\n",
    "        X[col] = X[col].fillna('MISSING')\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the wrangle function\n",
    "X_train = wrangle(X_train)\n",
    "X_val = wrangle(X_val)\n",
    "test_features = wrangle(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe with all train columns except id and date_recorded\n",
    "X_train = X_train.drop(columns='id')\n",
    "\n",
    "# get a list of numeric features\n",
    "numeric_features = X_train.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# get a series with the cardinality of the nonnumeric features\n",
    "cardinality = X_train.select_dtypes(exclude='number').nunique()\n",
    "\n",
    "# get list of categorical features with cardinality < 50\n",
    "categorical_features = cardinality[cardinality <= 50].index.tolist()\n",
    "\n",
    "# combine the lists\n",
    "features = numeric_features + categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[features]\n",
    "X_val = X_val[features]\n",
    "test_features = test_features[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder: fit transform on train, transform on val and test\n",
    "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_val_encoded = encoder.transform(X_val)\n",
    "test_features_encoded = encoder.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values with IterativeImputer\n",
    "encoded_columns = X_train_encoded.columns.tolist()\n",
    "X_train = pd.DataFrame(IterativeImputer().fit_transform(X_train_encoded), columns=encoded_columns)\n",
    "X_val = pd.DataFrame(IterativeImputer().fit_transform(X_val_encoded), columns=encoded_columns)\n",
    "test_features = pd.DataFrame(IterativeImputer().fit_transform(test_features_encoded), columns=encoded_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "------------------------------\n",
      "Train Accuracy: 0.9959595959595959\n",
      "Validation Accuracy: 0.731986531986532\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "print('Decision Tree')\n",
    "print('---'*10)\n",
    "print(f'Train Accuracy: {dt_model.score(X_train, y_train)}')\n",
    "print(f'Validation Accuracy: {dt_model.score(X_val, y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephensinclair/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.7963804713804714\n"
     ]
    }
   ],
   "source": [
    "# so far this seems like my best result\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print('Validation Accuracy', model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write submission csv file\n",
    "# submission = sample_submission.copy()\n",
    "# submission['status_group'] = model.predict(test_features)\n",
    "# submission.to_csv('submission-11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try hyperparameter tuning on Random Forest\n",
    "# then try XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.7851851851851852\n"
     ]
    }
   ],
   "source": [
    "# what about gradient boosting, n_estimators=1000\n",
    "# I guess I'll take a walk\n",
    "gb_model = GradientBoostingClassifier(n_estimators=1000)\n",
    "gb_model.fit(X_train, y_train)\n",
    "print('Validation Accuracy', gb_model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.7854377104377105\n"
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingClassifier(n_estimators=10000)\n",
    "gb_model.fit(X_train, y_train)\n",
    "print('Validation Accuracy', gb_model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.8071548821548822\n"
     ]
    }
   ],
   "source": [
    "# so far this seems like my best result\n",
    "model = RandomForestClassifier(n_estimators=1000, max_depth=25)\n",
    "model.fit(X_train, y_train)\n",
    "print('Validation Accuracy', model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write submission csv file\n",
    "# submission = sample_submission.copy()\n",
    "# submission['status_group'] = model.predict(test_features)\n",
    "# submission.to_csv('submission-30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.806986531986532\n"
     ]
    }
   ],
   "source": [
    "# so far this seems like my best result\n",
    "model = RandomForestClassifier(n_estimators=1000, criterion='entropy')\n",
    "model.fit(X_train, y_train)\n",
    "print('Validation Accuracy', model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write submission csv file\n",
    "# submission = sample_submission.copy()\n",
    "# submission['status_group'] = model.predict(test_features)\n",
    "# submission.to_csv('submission-32.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
