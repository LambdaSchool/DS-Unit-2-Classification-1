{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "from fancyimpute import IterativeImputer\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and split into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train_features.csv & train_labels.csv\n",
    "train = pd.merge(pd.read_csv('https://drive.google.com/uc?export=download&id=14ULvX0uOgftTB2s97uS8lIx1nHGQIB0P'), \n",
    "                 pd.read_csv('https://drive.google.com/uc?export=download&id=1r441wLr7gKGHGLyPpKauvCuUOU556S2f'))\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "test = pd.read_csv('https://drive.google.com/uc?export=download&id=1wvsYl9hbRbZuIuoaLWCsW_kbcxCdocHz')\n",
    "sample_submission = pd.read_csv('https://drive.google.com/uc?export=download&id=1kfJewnmhowpUo381oSn3XqsQ6Eto23XV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 41), (11880, 41), (14358, 40), (14358, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train and validation sets\n",
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
    "                              stratify=train['status_group'])\n",
    "\n",
    "train.shape, val.shape, test.shape, sample_submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(X):\n",
    "    \"\"\"Wrangles train, validate, and test sets in the same way\"\"\"\n",
    "    X = X.copy()\n",
    "\n",
    "    # Convert date_recorded to datetime\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract components from date_recorded, then drop the original column\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    X['month_recorded'] = X['date_recorded'].dt.month\n",
    "    X['day_recorded'] = X['date_recorded'].dt.day\n",
    "    X = X.drop(columns='date_recorded')\n",
    "    \n",
    "    # Engineer feature: how many years from construction_year to date_recorded\n",
    "    X['years'] = X['year_recorded'] - X['construction_year']    \n",
    "    \n",
    "    # Drop recorded_by (never varies) and id (always varies, random)\n",
    "    unusable_variance = ['recorded_by', 'id']\n",
    "    X = X.drop(columns=unusable_variance)\n",
    "    \n",
    "    # Drop duplicate columns\n",
    "    duplicate_columns = ['quantity_group']\n",
    "    X = X.drop(columns=duplicate_columns)\n",
    "    \n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these like null values\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, np.nan)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values\n",
    "    cols_with_zeros = ['construction_year', 'longitude', 'latitude', 'gps_height', 'population']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        \n",
    "#     # For categoricals with missing values, fill with the category 'MISSING'\n",
    "#     categoricals = X.select_dtypes(exclude='number').columns\n",
    "#     for col in categoricals:\n",
    "#         X[col] = X[col].fillna('MISSING')\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The status_group column is the target\n",
    "target = 'status_group'\n",
    "\n",
    "# Get a dataframe with all train columns except the target\n",
    "train_features = train.drop(columns=[target])\n",
    "\n",
    "# Get a list of the numeric features\n",
    "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Get a series with the cardinality of the nonnumeric features\n",
    "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
    "\n",
    "# Get a list of all categorical features with cardinality <= 50\n",
    "categorical_features = cardinality[cardinality <= 50].index.tolist()\n",
    "\n",
    "# Combine the lists \n",
    "features = numeric_features + categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "funder                    1686\n",
       "installer                 1933\n",
       "wpt_name                 30667\n",
       "basin                        9\n",
       "subvillage               17297\n",
       "region                      21\n",
       "lga                        125\n",
       "ward                      2084\n",
       "public_meeting               2\n",
       "scheme_management           11\n",
       "scheme_name               2548\n",
       "permit                       2\n",
       "extraction_type             18\n",
       "extraction_type_group       13\n",
       "extraction_type_class        7\n",
       "management                  12\n",
       "management_group             5\n",
       "payment                      7\n",
       "payment_type                 7\n",
       "water_quality                8\n",
       "quality_group                6\n",
       "quantity                     5\n",
       "source                      10\n",
       "source_type                  7\n",
       "source_class                 3\n",
       "waterpoint_type              7\n",
       "waterpoint_type_group        6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cat = ['public_meeting',\n",
    "               'permit',\n",
    "               'management_group',\n",
    "               'payment_type',\n",
    "               'quantity',\n",
    "               'waterpoint_type_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector \n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47520, 33)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder: fit_transform on train, transform on val & test\n",
    "encoder = ce.OneHotEncoder(use_cat_names=True, cols=one_hot_cat)\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_val = encoder.transform(X_val)\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47520, 56)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encoding \n",
    "X_train_encoded = ce.OrdinalEncoder().fit_transform(X_train)\n",
    "X_val_encoded = ce.OrdinalEncoder().fit_transform(X_val)\n",
    "X_test_encoded = ce.OrdinalEncoder().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative imputation\n",
    "imputer = IterativeImputer(n_iter=5, sample_posterior=True)\n",
    "column_names = X_train_encoded.columns.values.tolist()\n",
    "\n",
    "X_train_filled = pd.DataFrame(imputer.fit_transform(X_train_encoded), columns=column_names)\n",
    "X_val_filled = pd.DataFrame(imputer.fit_transform(X_val_encoded), columns=column_names)\n",
    "X_test_filled = pd.DataFrame(imputer.fit_transform(X_test_encoded), columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>year_recorded</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group_communal standpipe</th>\n",
       "      <th>waterpoint_type_group_other</th>\n",
       "      <th>waterpoint_type_group_hand pump</th>\n",
       "      <th>waterpoint_type_group_improved spring</th>\n",
       "      <th>waterpoint_type_group_cattle trough</th>\n",
       "      <th>waterpoint_type_group_dam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-3595.55</td>\n",
       "      <td>37.22</td>\n",
       "      <td>-6.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>413.00</td>\n",
       "      <td>2005.00</td>\n",
       "      <td>2011.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height  longitude  latitude  num_private  region_code  \\\n",
       "0        0.00    -3595.55      37.22     -6.53         0.00         5.00   \n",
       "\n",
       "   district_code  population  construction_year  year_recorded  \\\n",
       "0           1.00      413.00            2005.00        2011.00   \n",
       "\n",
       "             ...              source  source_type  source_class  \\\n",
       "0            ...                1.00         1.00          1.00   \n",
       "\n",
       "   waterpoint_type  waterpoint_type_group_communal standpipe  \\\n",
       "0             1.00                                      1.00   \n",
       "\n",
       "   waterpoint_type_group_other  waterpoint_type_group_hand pump  \\\n",
       "0                         0.00                             0.00   \n",
       "\n",
       "   waterpoint_type_group_improved spring  waterpoint_type_group_cattle trough  \\\n",
       "0                                   0.00                                 0.00   \n",
       "\n",
       "   waterpoint_type_group_dam  \n",
       "0                       0.00  \n",
       "\n",
       "[1 rows x 56 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_filled.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model, make predictions, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=4, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model on training data\n",
    "model = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=100,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=1,\n",
    " colsample_bytree=0.8,\n",
    " booster='dart',\n",
    " n_jobs=-1,\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "model.fit(X_train_filled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "preds = model.predict(X_val_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7094276094276094\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_val, preds)\n",
    "print(f'Accuracy Score: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RandomForestClassifier(n_estimators=800, max_depth=25)\n",
    "model2.fit(X_train_filled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = model2.predict(X_val_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7319023569023569\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_val, preds2)\n",
    "print(f'Accuracy Score: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
